{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Práctica 3: Caracterización y Clasificación de Texturas\n",
    "- Martínez Ostoa Néstor Iván\n",
    "- Ramírez Bondi Jorge Alejandro"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Construcción de imágenes de prueba y entrenamiento\n",
    "\n",
    "Para construir el conjunto de imágenes de prueba y entrenamiento tomamos un subconjunto de las texturas de [Brodatz](http://sipi.usc.edu/database/database.php?volume=textures), las subdividimos en $n$ ventanas de tamaños iguales y separamos en ventanas de prueba y entrenamiento."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "def split_image(image, num_images, verbose=False):\n",
    "    \"\"\"\n",
    "    Splits an image (ndarray) into 'num_images' images and returns the splitted\n",
    "    images\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    'image': numpy ndarray\n",
    "        'image' must be a squared 2D numpy array \n",
    "\n",
    "    'num_images': int\n",
    "        indicates the number of images to be returned\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    'splitted_images': numpy ndarray\n",
    "    \"\"\"\n",
    "    (width, height) = image.shape\n",
    "    if width != height: raise Exception('image must be a squared ndarray')\n",
    "    num_windows = int(np.sqrt(num_images))\n",
    "    window_size = width // num_windows\n",
    "    if verbose:\n",
    "        print(f\"\\tImage of size ({width}x{height}). Window size: {window_size}\")\n",
    "    splitted_images = []\n",
    "    y = 0\n",
    "    while (y+window_size <= height):\n",
    "        x = 0\n",
    "        while (x+window_size <= width):\n",
    "            if verbose: print(f\"\\t({x},{x+window_size}:{y},{y+window_size})\\t\", end='')\n",
    "            splitted_images.append(image[x:x+window_size, y:y+window_size])\n",
    "            x += window_size\n",
    "        if verbose: print()\n",
    "        y += window_size\n",
    "    splitted_images = np.array(splitted_images)\n",
    "    return splitted_images"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "def save_images(base_path, img_name, images, prefix):\n",
    "    img_name = img_name.split('.')\n",
    "    base_name = img_name[0]\n",
    "    extension = img_name[1]\n",
    "    for idx, img in enumerate(images):\n",
    "        im = Image.fromarray(img)\n",
    "        im.save(base_path + prefix + '/' + base_name + '_' + str(idx) + '.' + extension)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "textures_path = '../textures/train/'\n",
    "textures_names = os.listdir(textures_path)\n",
    "base_path = 'imgs/'\n",
    "num_windows = 9\n",
    "for texture_name in textures_names:\n",
    "    if texture_name[0] == '.': continue\n",
    "    print(f\"Processing {texture_name}\")\n",
    "    # Image reading\n",
    "    rgb_img = cv2.imread(textures_path + texture_name)\n",
    "    gray_img = cv2.cvtColor(rgb_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Image splitting\n",
    "    images = split_image(gray_img, num_windows, verbose=False)\n",
    "    test_imgs, train_imgs = train_test_split(images, test_size=0.2)\n",
    "\n",
    "    # Image saving\n",
    "    save_images(base_path, texture_name, test_imgs, prefix='test')\n",
    "    save_images(base_path, texture_name, train_imgs, prefix='train')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Processing Piedras.jpg\n",
      "Processing D16.bmp\n",
      "Processing D6.bmp\n",
      "Processing D64.bmp\n",
      "Processing D49.bmp\n",
      "Processing D46.bmp\n",
      "Processing Piedras3.jpg\n",
      "Processing D101.bmp\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Vectores característicos de entrenamiento\n",
    "Para esta seccción utilizamos las imágenes de entrenamiento"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "import mahotas as mt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "def get_features(img, verbose=False):\n",
    "    \"\"\"\n",
    "    Returns the 13 statistics defined by Haralick for each image that is passed\n",
    "    as input:\n",
    "        - Angular second moment\n",
    "        - Contrast\n",
    "        - Correlation\n",
    "        - Variance\n",
    "        - Inverse Difference Moment\n",
    "        - Sum Average\n",
    "        - Sum Variance\n",
    "        - Sum Entropy\n",
    "        - Entropy\n",
    "        - Difference Variance\n",
    "        - Difference Entropy\n",
    "        - Info Measure of Correlation 1\n",
    "        - Info Measure of Correlation 2\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    'img': ndarray\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    'feature_vector': ndarray\n",
    "        each element inside 'feature_vector' represents one of the 13th Haralick \n",
    "        statistics. By using mean(0) we are getting the mean of the 13 Haralick\n",
    "        statistics per co-ocurrence matrix direction. Otherwise, 'feature_vector'\n",
    "        would have 4x13 dimensions (one per matrix direction)\n",
    "    \"\"\"\n",
    "    feature_vector = mt.features.haralick(img).mean(0) # Dimensions: (1x13)\n",
    "    return feature_vector"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "train_features = []\n",
    "train_labels = []\n",
    "\n",
    "path = 'imgs/train/'\n",
    "imgs_names = os.listdir(path)\n",
    "for img_name in imgs_names:\n",
    "    if img_name[0] == '.': continue\n",
    "    class_name = img_name.split('_')[0]\n",
    "    print(f\"Processing {class_name}\")\n",
    "    # Image reading\n",
    "    img = cv2.cvtColor(cv2.imread(path + img_name), cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Feature extraction\n",
    "    img_features = get_features(img, verbose=True)\n",
    "    train_features.append(img_features)\n",
    "    train_labels.append(class_name)\n",
    "\n",
    "train_features = np.array(train_features)\n",
    "train_labels = np.array(train_labels)\n",
    "print(f\"\\n-----\\nNumber of features: {train_features.shape}\")\n",
    "print(f\"Number of labels: {train_labels.shape}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Processing D46\n",
      "Processing D46\n",
      "Processing D64\n",
      "Processing Piedras3\n",
      "Processing Piedras3\n",
      "Processing D64\n",
      "Processing D6\n",
      "Processing D6\n",
      "Processing D16\n",
      "Processing D16\n",
      "Processing Piedras\n",
      "Processing Piedras\n",
      "Processing D49\n",
      "Processing D101\n",
      "Processing D101\n",
      "Processing D49\n",
      "\n",
      "-----\n",
      "Number of features: (16, 13)\n",
      "Number of labels: (16,)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "train_labels"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['D46', 'D46', 'D64', 'Piedras3', 'Piedras3', 'D64', 'D6', 'D6',\n",
       "       'D16', 'D16', 'Piedras', 'Piedras', 'D49', 'D101', 'D101', 'D49'],\n",
       "      dtype='<U8')"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Clasificador\n",
    "\n",
    "Para la clasificación, utilizamos dos clasificadores distintos:\n",
    "\n",
    "1. Máquina de soporte vectorial (SVM)\n",
    "2. KNN"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Entrenamiento"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "svm = LinearSVC(random_state=10, max_iter=1e8)\n",
    "svm.fit(train_features, train_labels)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LinearSVC(max_iter=100000000.0, random_state=10)"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn.fit(train_features, train_labels)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Predicciones y Validación"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "def get_unique_features(imgs_names):\n",
    "    features = set()\n",
    "    for name in imgs_names:\n",
    "        class_name = name.split('_')[0]\n",
    "        features.add(class_name)\n",
    "    return np.array(list(features))\n",
    "\n",
    "def num_feature_from_string(unique_features, str_feature):\n",
    "    idx = 0\n",
    "    for f in unique_features:\n",
    "        if f == str_feature: return idx\n",
    "        idx += 1\n",
    "    return -1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "svm_pred = []\n",
    "knn_pred = []\n",
    "real_features = []\n",
    "\n",
    "path = 'imgs/test/'\n",
    "imgs_names = os.listdir(path)\n",
    "unique_features = get_unique_features(imgs_names[1:])\n",
    "for idx, img_name in enumerate(imgs_names):\n",
    "    if img_name[0] == '.': continue\n",
    "    class_name = img_name.split('_')[0]\n",
    "    real_features.append(num_feature_from_string(unique_features, class_name))\n",
    "    \n",
    "    # Image reading\n",
    "    img = cv2.cvtColor(cv2.imread(path + img_name), cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Feature extraction\n",
    "    features = get_features(img)\n",
    "\n",
    "    # SVM prediction\n",
    "    svm_prediction = svm.predict(features.reshape(1, -1))[0]\n",
    "    svm_pred.append(num_feature_from_string(unique_features, svm_prediction))\n",
    "\n",
    "    # KNN prediction\n",
    "    knn_prediction = knn.predict(features.reshape(1, -1))[0]\n",
    "    knn_pred.append(num_feature_from_string(unique_features, knn_prediction))\n",
    "\n",
    "    #if idx < 10:\n",
    "        # Image showing\n",
    "     #   cv2.putText(img, knn_prediction, (20,30), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (255,0,0))\n",
    "      #  cv2.imshow('Test image', img)\n",
    "       # cv2.waitKey(0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Evaluación entre SVM y KNN\n",
    "\n",
    "Para evaluar el desempeño de la clasificación entre SVM y KNN, utilizamos **f1-score** pues es una métrica que combina la precisión y *recall*. Por un lado, la precisión es una métrica que nos ayuda a minimizar el número de falsos positivos. Por otro lado, *recall* es una métrica que es importante en experimentos de índole médica, por ejemplo, pues queremos minimizar la posibilidad de que se nos escapen los casos positivos. Por esta razón, **f1-score** es la mejor métrica pues combina estas dos métricas en una sola. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "from sklearn.metrics import f1_score"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "svm_f1 = f1_score(real_features, svm_pred, average='macro')\n",
    "knn_f1 = f1_score(real_features, knn_pred, average='macro')\n",
    "print(f'F1 score for SVM: {svm_f1}')\n",
    "print(f'F1 score for KNN: {knn_f1}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "F1 score for SVM: 0.2885416666666667\n",
      "F1 score for KNN: 0.45208333333333334\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Evaluación sobre imágenes compuestas"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "path = 'imgs/mixed/'\n",
    "imgs_names = os.listdir(path)\n",
    "for idx, img_name in enumerate(imgs_names):\n",
    "    if img_name[0] == '.': continue\n",
    "    class_name = img_name.split('_')[0]\n",
    "    print(class_name)\n",
    "    real_features.append(num_feature_from_string(unique_features, class_name))\n",
    "\n",
    "    # Image reading\n",
    "    img = cv2.cvtColor(cv2.imread(path + img_name), cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Image splitting (four windows)\n",
    "    images = split_image(img, num_images=4, verbose=False)\n",
    "\n",
    "    # Image showing\n",
    "    for img_idx, img in enumerate(images):\n",
    "        features = get_features(img)\n",
    "        prediction = knn.predict(features.reshape(1, -1))[0]\n",
    "        print(f\"\\tPrediction #{img_idx + 1}: {prediction}\")\n",
    "        #cv2.imshow('Test', img)\n",
    "        #cv2.waitKey(0)\n",
    "\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "imgCompuesta2.png\n",
      "\tPrediction #1: D16\n",
      "\tPrediction #2: D46\n",
      "\tPrediction #3: D46\n",
      "\tPrediction #4: D101\n",
      "imgCompuesta3.png\n",
      "\tPrediction #1: D101\n",
      "\tPrediction #2: D46\n",
      "\tPrediction #3: D46\n",
      "\tPrediction #4: D46\n",
      "imgCompuesta1.png\n",
      "\tPrediction #1: D16\n",
      "\tPrediction #2: D49\n",
      "\tPrediction #3: D46\n",
      "\tPrediction #4: D101\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "unique_features"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.2",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.2 64-bit"
  },
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}