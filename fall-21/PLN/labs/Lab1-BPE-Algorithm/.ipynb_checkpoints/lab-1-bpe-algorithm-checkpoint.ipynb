{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práctica 1 - Algoritmo BPE\n",
    "\n",
    "- Martínez Ostoa Néstor I.\n",
    "- Procesamiento de Lenguaje Natural\n",
    "- IeC - FI - UNAM\n",
    "\n",
    "--- \n",
    "**Objetivo**: Preprocesar un corpus a partir de métodos basados en lenguajes formales y tokenizarlo en subpalabras\n",
    "\n",
    "De manera general, hay que seguir los siguientes pasos: \n",
    "\n",
    "1. Selección del corpus\n",
    "2. Limpieza del corpus\n",
    "3. Algoritmo BPE\n",
    "\n",
    "## Selección del corpus\n",
    "\n",
    "- Escoger un corpus de cualquier idioma y de un tamãno mayor a $10000$\n",
    "\n",
    "--- \n",
    "\n",
    "**Corpus elegido:** Don't Patronize Me! dataset ([link](https://github.com/Perez-AlmendrosC/dontpatronizeme))\n",
    "\n",
    "- Este corpus contiene $10,637$ párrafos extraídos de artículos de noticias con el objetivo principal de realizar un análisis para detectar lenguaje condescendiente (*patronizing and condescending language PCL*) en grupos socialmente vulnerables (refugiados, familias pobres, personas sin casa, etc)\n",
    "- Cada uno de estos párrafos están anotados con etiquetas que indican el tipo de lenguaje PCL que se encuentra en él (si es que está presente). Los párrafos se extrajeron del corpus [News on Web (NOW)](https://www.english-corpora.org/now/)\n",
    "- [Link al paper principal](https://aclanthology.org/2020.coling-main.518/)\n",
    "\n",
    "---\n",
    "\n",
    "**Estructura del corpus**\n",
    "\n",
    "- De manera general, el dataset contiene párrafos anotados con una etiqueta con valores entre $0$ y $4$ que indican el nivel de lenguaje PCL presente\n",
    "- Cada instancia del dataset está conformada de la siguiente manera:\n",
    "    - ```<doc-id>```: id del documento dentro del corpus NOW\n",
    "    - ```<keyword>```: término de búsqueda utilizado para extraer textos relacionados con una comunidad en específico\n",
    "    - ```<country-code>```: código de dos letras ISO Alpha-2\n",
    "    - ```<paragraph>```: párrafo perteneciente al ```<keyword>```\n",
    "    - ```<label>```: entero que indica el nivel de PCL presente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>country-code</th>\n",
       "      <th>paragraph</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@@23953477</td>\n",
       "      <td>in-need</td>\n",
       "      <td>in</td>\n",
       "      <td>The ones in need of constant medical care are ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@@4703096</td>\n",
       "      <td>immigrant</td>\n",
       "      <td>jm</td>\n",
       "      <td>NBC and Spanish-language Univision both declin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@@25567226</td>\n",
       "      <td>in-need</td>\n",
       "      <td>hk</td>\n",
       "      <td>A second T-Home project is being launched in t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@@1824078</td>\n",
       "      <td>poor-families</td>\n",
       "      <td>tz</td>\n",
       "      <td>Camfed would like to see this trend reversed ....</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@@1921089</td>\n",
       "      <td>refugee</td>\n",
       "      <td>tz</td>\n",
       "      <td>Kagunga village was reported to lack necessary...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       doc_id        keyword country-code  \\\n",
       "0  @@23953477        in-need           in   \n",
       "1   @@4703096      immigrant           jm   \n",
       "2  @@25567226        in-need           hk   \n",
       "3   @@1824078  poor-families           tz   \n",
       "4   @@1921089        refugee           tz   \n",
       "\n",
       "                                           paragraph  label  \n",
       "0  The ones in need of constant medical care are ...      0  \n",
       "1  NBC and Spanish-language Univision both declin...      0  \n",
       "2  A second T-Home project is being launched in t...      0  \n",
       "3  Camfed would like to see this trend reversed ....      4  \n",
       "4  Kagunga village was reported to lack necessary...      0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"../dontpatronizeme_v1.3/dontpatronizeme_pcl.tsv\"\n",
    "\n",
    "cols = [\"doc_id\", \"keyword\", \"country-code\", \"paragraph\", \"label\"]\n",
    "df = pd.read_csv(path, sep='\\t', skiprows=4, names=cols)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpieza del corpus\n",
    "\n",
    "- Eliminar signos de puntuación, de interrogación, admiración y elementos no léxicos y en general elementos ruidosos\n",
    "\n",
    "--- \n",
    "\n",
    "**Valores nulos**\n",
    "\n",
    "Comenzamos observando un panorama general del dataset para encontrar posibles valores nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>country-code</th>\n",
       "      <th>paragraph</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5744</th>\n",
       "      <td>@@16852855</td>\n",
       "      <td>migrant</td>\n",
       "      <td>ke</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          doc_id  keyword country-code paragraph  label\n",
       "5744  @@16852855  migrant           ke       NaN      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viendo que el dataset cuenta con un párrafo nulo, lo podemos eliminar dado que no contamos con acceso a ese párrafo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>country-code</th>\n",
       "      <th>paragraph</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [doc_id, keyword, country-code, paragraph, label]\n",
       "Index: []"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "df[df.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Construcción del corpus**\n",
    "\n",
    "Una vez que eliminamos valores nulos, podemos pasar a la construcción del corpus. En una etapa inicial, el corpus será un dataframe de Pandas en donde cada elemento corresponderá con un párrafo del dataset original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_corpus(df):\n",
    "    corpus = []\n",
    "    for _, row in df.iterrows():\n",
    "        p = row[\"paragraph\"]\n",
    "        corpus.append(p)\n",
    "    return pd.DataFrame({'paragraph': corpus})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 10,059\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paragraph</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The ones in need of constant medical care are ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NBC and Spanish-language Univision both declin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A second T-Home project is being launched in t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Camfed would like to see this trend reversed ....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kagunga village was reported to lack necessary...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           paragraph\n",
       "0  The ones in need of constant medical care are ...\n",
       "1  NBC and Spanish-language Univision both declin...\n",
       "2  A second T-Home project is being launched in t...\n",
       "3  Camfed would like to see this trend reversed ....\n",
       "4  Kagunga village was reported to lack necessary..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_df = build_corpus(df)\n",
    "print(\"Number of documents:\", \"{:,}\".format(corpus_df.shape[0]))\n",
    "corpus_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conteo de tokens**\n",
    "\n",
    "Verificamos la cantidad de tokens presentes en el corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_tokens(corpus):\n",
    "    \"\"\"\n",
    "    corpus: Pandas DataFrame\n",
    "    \"\"\"\n",
    "    token_count = 0\n",
    "    for _, row in corpus.iterrows():\n",
    "        tokens = row[\"paragraph\"].split(' ')\n",
    "        token_count += len(tokens)\n",
    "    return token_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens: 513,753\n"
     ]
    }
   ],
   "source": [
    "token_count = count_tokens(corpus_df)\n",
    "print(\"Number of tokens:\", \"{:,}\".format(token_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Limpieza de un documento ejemplo**\n",
    "\n",
    "- Eliminación de espacios en blanco\n",
    "- Eliminación de caracteres especiales\n",
    "- Eliminación de stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_whitespaces(doc):\n",
    "    new_doc = doc.strip()\n",
    "    return re.sub(\"\\s+\", \" \", new_doc)\n",
    "\n",
    "def clean_punctuation(doc):\n",
    "    new_doc = doc.replace('-', ' ')\n",
    "    new_doc = doc.replace('/', ' ')\n",
    "    new_doc = \"\".join([w for w in new_doc if w not in string.punctuation])\n",
    "    return clean_whitespaces(new_doc)\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words.remove('no')\n",
    "def clean_stopwords(doc):\n",
    "    doc = doc.lower().split(' ')\n",
    "    new_p = [w for w in doc if w not in stop_words]\n",
    "    new_doc = \" \".join(new_p)\n",
    "    return clean_whitespaces(new_doc)\n",
    "\n",
    "def clean_document(doc):\n",
    "    new_doc = clean_punctuation(doc)\n",
    "    new_doc = clean_stopwords(new_doc)\n",
    "    return new_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document of choice:\n",
      "-------------------\n",
      "Being part of a wider movement on protecting the human rights of vulnerable people and advocating for more effective responses from governments and other regulatory agencies\n",
      "\n",
      "Clean document:\n",
      "-----------------\n",
      "part wider movement protecting human rights vulnerable people advocating effective responses governments regulatory agencies\n"
     ]
    }
   ],
   "source": [
    "# Elección de un documento\n",
    "doc = corpus_df.iloc[30, 0]\n",
    "print(f\"Document of choice:\\n-------------------\\n{doc}\\n\")\n",
    "\n",
    "# Documento limpio\n",
    "new_doc = clean_document(doc)\n",
    "print(f\"Clean document:\\n-----------------\\n{new_doc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Limpieza de todo el corpus**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paragraph</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ones need constant medical care kept admitted ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nbc spanishlanguage univision declined air sho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>second thome project launched third quarter on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>camfed would like see trend reversed would lik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kagunga village reported lack necessary social...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           paragraph\n",
       "0  ones need constant medical care kept admitted ...\n",
       "1  nbc spanishlanguage univision declined air sho...\n",
       "2  second thome project launched third quarter on...\n",
       "3  camfed would like see trend reversed would lik...\n",
       "4  kagunga village reported lack necessary social..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_docs = []\n",
    "for idx, row in corpus_df.iterrows():\n",
    "    p = row['paragraph']\n",
    "    #print(f\"Current doc[{idx}]:\\n---------------\\n{p}\\n\")\n",
    "    clean_doc = clean_document(p)\n",
    "    #print(f\"Cleaned doc:\\n------------\\n{clean_doc}\\n\\n\")\n",
    "    clean_docs.append(clean_doc)\n",
    "\n",
    "clean_corpus_df = pd.DataFrame({'paragraph': clean_docs})\n",
    "clean_corpus_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algoritmo BPE\n",
    "\n",
    "- Aplicar el algoritmo BPE al corpus para obtener subpalabras:\n",
    "    - Formar un vocabulario inicial: cada palabra se asocia a la cadena de subpalabras\n",
    "    - Seleccionar el número de iteraciones que mejor se adapte al corpus elegido\n",
    "    - Obtener el vocabulario final: cada palabra se asocia a la cadena de subpalabras\n",
    "    - Sustituir en el corpus las palabras por la tokenización en subpalabras obtenidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e8e5b3663f46d3e30364c3fda14ff5830effa7f7e28c52bdd1713a14cbd3cb6a"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
