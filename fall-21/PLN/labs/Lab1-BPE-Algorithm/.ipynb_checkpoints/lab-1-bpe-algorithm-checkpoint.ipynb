{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práctica 1 - Algoritmo BPE\n",
    "\n",
    "- Martínez Ostoa Néstor I.\n",
    "- Procesamiento de Lenguaje Natural\n",
    "- IeC - FI - UNAM\n",
    "\n",
    "--- \n",
    "**Objetivo**: Preprocesar un corpus a partir de métodos basados en lenguajes formales y tokenizarlo en subpalabras\n",
    "\n",
    "De manera general, hay que seguir los siguientes pasos: \n",
    "\n",
    "1. Selección del corpus\n",
    "2. Limpieza del corpus\n",
    "3. Algoritmo BPE\n",
    "\n",
    "## Selección del corpus\n",
    "\n",
    "- Escoger un corpus de cualquier idioma y de un tamãno mayor a $10000$\n",
    "\n",
    "--- \n",
    "\n",
    "**Corpus elegido:** Don't Patronize Me! dataset ([link](https://github.com/Perez-AlmendrosC/dontpatronizeme))\n",
    "\n",
    "- Este corpus contiene $10,637$ párrafos extraídos de artículos de noticias con el objetivo principal de realizar un análisis para detectar lenguaje condescendiente (*patronizing and condescending language PCL*) en grupos socialmente vulnerables (refugiados, familias pobres, personas sin casa, etc)\n",
    "- Cada uno de estos párrafos están anotados con etiquetas que indican el tipo de lenguaje PCL que se encuentra en él (si es que está presente). Los párrafos se extrajeron del corpus [News on Web (NOW)](https://www.english-corpora.org/now/)\n",
    "- [Link al paper principal](https://aclanthology.org/2020.coling-main.518/)\n",
    "\n",
    "---\n",
    "\n",
    "**Estructura del corpus**\n",
    "\n",
    "- De manera general, el dataset contiene párrafos anotados con una etiqueta con valores entre $0$ y $4$ que indican el nivel de lenguaje PCL presente\n",
    "- Cada instancia del dataset está conformada de la siguiente manera:\n",
    "    - ```<doc-id>```: id del documento dentro del corpus NOW\n",
    "    - ```<keyword>```: término de búsqueda utilizado para extraer textos relacionados con una comunidad en específico\n",
    "    - ```<country-code>```: código de dos letras ISO Alpha-2\n",
    "    - ```<paragraph>```: párrafo perteneciente al ```<keyword>```\n",
    "    - ```<label>```: entero que indica el nivel de PCL presente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>country-code</th>\n",
       "      <th>paragraph</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@@23953477</td>\n",
       "      <td>in-need</td>\n",
       "      <td>in</td>\n",
       "      <td>The ones in need of constant medical care are ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@@4703096</td>\n",
       "      <td>immigrant</td>\n",
       "      <td>jm</td>\n",
       "      <td>NBC and Spanish-language Univision both declin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@@25567226</td>\n",
       "      <td>in-need</td>\n",
       "      <td>hk</td>\n",
       "      <td>A second T-Home project is being launched in t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@@1824078</td>\n",
       "      <td>poor-families</td>\n",
       "      <td>tz</td>\n",
       "      <td>Camfed would like to see this trend reversed ....</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@@1921089</td>\n",
       "      <td>refugee</td>\n",
       "      <td>tz</td>\n",
       "      <td>Kagunga village was reported to lack necessary...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       doc_id        keyword country-code  \\\n",
       "0  @@23953477        in-need           in   \n",
       "1   @@4703096      immigrant           jm   \n",
       "2  @@25567226        in-need           hk   \n",
       "3   @@1824078  poor-families           tz   \n",
       "4   @@1921089        refugee           tz   \n",
       "\n",
       "                                           paragraph  label  \n",
       "0  The ones in need of constant medical care are ...      0  \n",
       "1  NBC and Spanish-language Univision both declin...      0  \n",
       "2  A second T-Home project is being launched in t...      0  \n",
       "3  Camfed would like to see this trend reversed ....      4  \n",
       "4  Kagunga village was reported to lack necessary...      0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"../dontpatronizeme_v1.3/dontpatronizeme_pcl.tsv\"\n",
    "\n",
    "cols = [\"doc_id\", \"keyword\", \"country-code\", \"paragraph\", \"label\"]\n",
    "df = pd.read_csv(path, sep='\\t', skiprows=4, names=cols)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpieza del corpus\n",
    "\n",
    "- Eliminar signos de puntuación, de interrogación, admiración y elementos no léxicos y en general elementos ruidosos\n",
    "\n",
    "--- \n",
    "\n",
    "**Valores nulos**\n",
    "\n",
    "Comenzamos observando un panorama general del dataset para encontrar posibles valores nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>country-code</th>\n",
       "      <th>paragraph</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5744</th>\n",
       "      <td>@@16852855</td>\n",
       "      <td>migrant</td>\n",
       "      <td>ke</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          doc_id  keyword country-code paragraph  label\n",
       "5744  @@16852855  migrant           ke       NaN      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viendo que el dataset cuenta con un párrafo nulo, lo podemos eliminar dado que no contamos con acceso a ese párrafo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>country-code</th>\n",
       "      <th>paragraph</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [doc_id, keyword, country-code, paragraph, label]\n",
       "Index: []"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "df[df.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Construcción del corpus**\n",
    "\n",
    "Una vez que eliminamos valores nulos, podemos pasar a la construcción del corpus. En una etapa inicial, el corpus será un dataframe de Pandas en donde cada elemento corresponderá con un párrafo del dataset original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_corpus(df):\n",
    "    corpus = []\n",
    "    for _, row in df.iterrows():\n",
    "        p = row[\"paragraph\"]\n",
    "        corpus.append(p)\n",
    "    return pd.DataFrame({'paragraph': corpus})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 10,059\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paragraph</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The ones in need of constant medical care are ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NBC and Spanish-language Univision both declin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A second T-Home project is being launched in t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Camfed would like to see this trend reversed ....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kagunga village was reported to lack necessary...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           paragraph\n",
       "0  The ones in need of constant medical care are ...\n",
       "1  NBC and Spanish-language Univision both declin...\n",
       "2  A second T-Home project is being launched in t...\n",
       "3  Camfed would like to see this trend reversed ....\n",
       "4  Kagunga village was reported to lack necessary..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_df = build_corpus(df)\n",
    "print(\"Number of documents:\", \"{:,}\".format(corpus_df.shape[0]))\n",
    "corpus_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conteo de tokens**\n",
    "\n",
    "Verificamos la cantidad de tokens presentes en el corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_tokens(corpus):\n",
    "    \"\"\"\n",
    "    corpus: Pandas DataFrame\n",
    "    \"\"\"\n",
    "    token_count = 0\n",
    "    for _, row in corpus.iterrows():\n",
    "        tokens = row[\"paragraph\"].split(' ')\n",
    "        token_count += len(tokens)\n",
    "    return token_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens: 513,753\n"
     ]
    }
   ],
   "source": [
    "token_count = count_tokens(corpus_df)\n",
    "print(\"Number of tokens:\", \"{:,}\".format(token_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Limpieza de un documento ejemplo**\n",
    "\n",
    "- Eliminación de espacios en blanco\n",
    "- Eliminación de caracteres especiales\n",
    "- Eliminación de stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_whitespaces(doc):\n",
    "    new_doc = doc.strip()\n",
    "    return re.sub(\"\\s+\", \" \", new_doc)\n",
    "\n",
    "def clean_punctuation(doc):\n",
    "    new_doc = doc.replace('-', ' ')\n",
    "    new_doc = doc.replace('/', ' ')\n",
    "    new_doc = \"\".join([w for w in new_doc if w not in string.punctuation])\n",
    "    new_doc = clean_numbers(new_doc)\n",
    "    return clean_whitespaces(new_doc)\n",
    "\n",
    "def clean_numbers(doc):\n",
    "    doc = doc.replace('1', ' ')\n",
    "    doc = doc.replace('2', ' ')\n",
    "    doc = doc.replace('3', ' ')\n",
    "    doc = doc.replace('4', ' ')\n",
    "    doc = doc.replace('5', ' ')\n",
    "    doc = doc.replace('6', ' ')\n",
    "    doc = doc.replace('7', ' ')\n",
    "    doc = doc.replace('8', ' ')\n",
    "    doc = doc.replace('9', ' ')\n",
    "    doc = doc.replace('0', ' ')\n",
    "    return doc\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words.remove('no')\n",
    "def clean_stopwords(doc):\n",
    "    doc = doc.lower().split(' ')\n",
    "    new_p = [w for w in doc if w not in stop_words]\n",
    "    new_doc = \" \".join(new_p)\n",
    "    return clean_whitespaces(new_doc)\n",
    "\n",
    "def clean_document(doc):\n",
    "    new_doc = clean_punctuation(doc)\n",
    "    new_doc = clean_stopwords(new_doc)\n",
    "    return new_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document of choice:\n",
      "-------------------\n",
      "Being part of a wider movement on protecting the human rights of vulnerable people and advocating for more effective responses from governments and other regulatory agencies\n",
      "\n",
      "Clean document:\n",
      "-----------------\n",
      "part wider movement protecting human rights vulnerable people advocating effective responses governments regulatory agencies\n"
     ]
    }
   ],
   "source": [
    "# Elección de un documento\n",
    "doc = corpus_df.iloc[30, 0]\n",
    "print(f\"Document of choice:\\n-------------------\\n{doc}\\n\")\n",
    "\n",
    "# Documento limpio\n",
    "new_doc = clean_document(doc)\n",
    "print(f\"Clean document:\\n-----------------\\n{new_doc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Limpieza de todo el corpus**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paragraph</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ones need constant medical care kept admitted ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nbc spanishlanguage univision declined air sho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>second thome project launched third quarter on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>camfed would like see trend reversed would lik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kagunga village reported lack necessary social...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           paragraph\n",
       "0  ones need constant medical care kept admitted ...\n",
       "1  nbc spanishlanguage univision declined air sho...\n",
       "2  second thome project launched third quarter on...\n",
       "3  camfed would like see trend reversed would lik...\n",
       "4  kagunga village reported lack necessary social..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_docs = []\n",
    "for idx, row in corpus_df.iterrows():\n",
    "    p = row['paragraph']\n",
    "    #print(f\"Current doc[{idx}]:\\n---------------\\n{p}\\n\")\n",
    "    clean_doc = clean_document(p)\n",
    "    #print(f\"Cleaned doc:\\n------------\\n{clean_doc}\\n\\n\")\n",
    "    clean_docs.append(clean_doc)\n",
    "\n",
    "clean_corpus_df = pd.DataFrame({'paragraph': clean_docs})\n",
    "clean_corpus_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Construcción del corpus final**\n",
    "\n",
    "- El corpus final será una lista de palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_final_corpus(df):\n",
    "    corpus = dict()\n",
    "    for _, row in df.iterrows():\n",
    "        paragraph = row['paragraph'].split(' ')\n",
    "        \n",
    "        # Iteración para obtener palabras y su frecuencia asociada\n",
    "        for word in paragraph:\n",
    "            if word not in corpus:\n",
    "                corpus[word] = 0\n",
    "            corpus[word] += 1\n",
    "\n",
    "    # Construcción del dataframe : <palabra, frecuencia>\n",
    "    df = pd.DataFrame({'word': list(corpus.keys()), 'frequency': list(corpus.values())})\n",
    "    df = df.sort_values(by='frequency', ascending=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Different words: 30,741\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>said</td>\n",
       "      <td>2174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>people</td>\n",
       "      <td>1858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>women</td>\n",
       "      <td>1769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>need</td>\n",
       "      <td>1354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>families</td>\n",
       "      <td>1347</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         word  frequency\n",
       "233      said       2174\n",
       "132    people       1858\n",
       "101     women       1769\n",
       "1        need       1354\n",
       "16   families       1347"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_df = build_final_corpus(clean_corpus_df)\n",
    "print(\"Different words:\", \"{:,}\".format(corpus_df.shape[0]))\n",
    "corpus_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algoritmo BPE\n",
    "\n",
    "- Aplicar el algoritmo BPE al corpus para obtener subpalabras:\n",
    "    - Formar un vocabulario inicial: cada palabra se asocia a la cadena de subpalabras\n",
    "    - Seleccionar el número de iteraciones $k$ que mejor se adapte al corpus elegido\n",
    "    - Obtener el vocabulario final: cada palabra se asocia a la cadena de subpalabras\n",
    "    - Sustituir en el corpus las palabras por la tokenización en subpalabras obtenidas\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrada\n",
    "- Lista de palabras (bajo un alfabeto $\\Sigma$) y sus frecuencias.\n",
    "- Número $k$ de iteraciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Sigma(df):\n",
    "    \"\"\"\n",
    "    df: Pandas DataFrame with words in one of its colums\n",
    "    \"\"\"\n",
    "    sigma = set()\n",
    "    for _, row in df.iterrows():\n",
    "        word = row['word']\n",
    "        for letter in word:\n",
    "            sigma.add(letter)\n",
    "    \n",
    "    return sorted(list(sigma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K: 5, Sigma: 26 elements\n",
      "\n",
      "['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>said</td>\n",
       "      <td>2174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>people</td>\n",
       "      <td>1858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>women</td>\n",
       "      <td>1769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>need</td>\n",
       "      <td>1354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>families</td>\n",
       "      <td>1347</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         word  frequency\n",
       "233      said       2174\n",
       "132    people       1858\n",
       "101     women       1769\n",
       "1        need       1354\n",
       "16   families       1347"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_df = build_final_corpus(clean_corpus_df)\n",
    "#corpus_df = corpus_df.iloc[500:510, :]\n",
    "sigma = get_Sigma(corpus_df)\n",
    "k = 5\n",
    "\n",
    "print(f\"K: {k}, Sigma: {len(sigma)} elements\")\n",
    "print(f\"\\n{sigma}\\n\")\n",
    "corpus_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inicialización\n",
    "\n",
    "- Se indican los símbolos del alfabeto $\\Sigma$ presentes en las palabras\n",
    "- Separación de cada palabra en su lista de símbolos: ```said``` $\\rightarrow$ ```s a i d```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Symbols in Sigma (26):\n",
      "\n",
      "['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Symbols in Sigma ({len(sigma)}):\\n\\n{sigma}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_words(df):\n",
    "    splitted_words = []\n",
    "    for _, row in df.iterrows():\n",
    "        word = row['word']\n",
    "        \n",
    "        #Split word into a list of its symbols\n",
    "        splitted_words.append(list(word))\n",
    "    \n",
    "    df['word'] = splitted_words\n",
    "    df = df.rename(columns={'word': 'symbols'})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbols</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>[s, a, i, d]</td>\n",
       "      <td>2174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>[p, e, o, p, l, e]</td>\n",
       "      <td>1858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>[w, o, m, e, n]</td>\n",
       "      <td>1769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[n, e, e, d]</td>\n",
       "      <td>1354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[f, a, m, i, l, i, e, s]</td>\n",
       "      <td>1347</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      symbols  frequency\n",
       "233              [s, a, i, d]       2174\n",
       "132        [p, e, o, p, l, e]       1858\n",
       "101           [w, o, m, e, n]       1769\n",
       "1                [n, e, e, d]       1354\n",
       "16   [f, a, m, i, l, i, e, s]       1347"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_df = split_words(corpus_df)\n",
    "corpus_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inducción\n",
    "- Por $k$ iteraciones hacer:\n",
    "    1. Se obtienen los pares de símbolos $[a_i,b_j]$ y sus frecuencias $f([a_i,b_j])$\n",
    "    2. Se obtiene $$[a,b]=\\arg\\max_{a_i,b_j}\\{f([a_i,b_j]):a_i,b_j\\in\\Sigma\\}$$\n",
    "    3. Se hace el reemplazo por el símbolo $ab$ en cada palabra del vocabulario: $$[a,b]\\mapsto ab$$\n",
    "    4. Se agrega el símbolo $ab$ al alfabeto $\\Sigma$\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pairs(df):\n",
    "    pairs_dict = dict()\n",
    "    for _, row in df.iterrows():\n",
    "        symbols = row['symbols']\n",
    "        frequency = row['frequency']\n",
    "        \n",
    "        pairs = []\n",
    "        for i in range(1, len(symbols)):\n",
    "            pairs.append((symbols[i-1], symbols[i]))\n",
    "            \n",
    "        for pair in pairs:\n",
    "            if pair not in pairs_dict:\n",
    "                pairs_dict[pair] = 0\n",
    "            pairs_dict[pair] += frequency\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        'pair': list(pairs_dict.keys()), \n",
    "        'frequency': list(pairs_dict.values())\n",
    "    })\n",
    "    return df\n",
    "\n",
    "def get_most_frequent_pair(pairs_df):\n",
    "    pairs_df_sorted = pairs_df.sort_values(by='frequency', ascending=False)\n",
    "    return pairs_df_sorted.iloc[0, 0]\n",
    "\n",
    "def update_corpus(df, pair_to_update):\n",
    "    symbols_updated = []\n",
    "    for idx, row in df.iterrows():\n",
    "        symbols = row['symbols']\n",
    "        \n",
    "        sym_idx = 0\n",
    "        joined_symbols = []\n",
    "        i = 1\n",
    "        while (i < len(symbols)):\n",
    "            if pair_to_update == (symbols[i-1], symbols[i]):\n",
    "                js = pair_to_update[0] + pair_to_update[1]\n",
    "                joined_symbols.append(js)\n",
    "                sym_idx = i\n",
    "                i += 2\n",
    "            else:\n",
    "                joined_symbols.append(symbols[i-1])\n",
    "                i += 1\n",
    "        if sym_idx != len(symbols)-1 and len(symbols) > 0:\n",
    "            joined_symbols.append(symbols[len(symbols)-1])\n",
    "            \n",
    "        symbols_updated.append(joined_symbols)\n",
    "    \n",
    "    return pd.DataFrame({\n",
    "        'symbols':symbols_updated,\n",
    "        'frequency':df['frequency']\n",
    "   })\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbols</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>[s, a, i, d]</td>\n",
       "      <td>2174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>[p, e, o, p, l, e]</td>\n",
       "      <td>1858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>[w, o, m, e, n]</td>\n",
       "      <td>1769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[n, e, e, d]</td>\n",
       "      <td>1354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[f, a, m, i, l, i, e, s]</td>\n",
       "      <td>1347</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      symbols  frequency\n",
       "233              [s, a, i, d]       2174\n",
       "132        [p, e, o, p, l, e]       1858\n",
       "101           [w, o, m, e, n]       1769\n",
       "1                [n, e, e, d]       1354\n",
       "16   [f, a, m, i, l, i, e, s]       1347"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------0-----------------\n",
      "Most frequent pair: ('i', 'n')\n",
      "\n",
      "------------1-----------------\n",
      "Most frequent pair: ('e', 'r')\n",
      "\n",
      "------------2-----------------\n",
      "Most frequent pair: ('e', 's')\n",
      "\n",
      "------------3-----------------\n",
      "Most frequent pair: ('e', 'n')\n",
      "\n",
      "------------4-----------------\n",
      "Most frequent pair: ('o', 'n')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(k):\n",
    "    print(f\"------------{i}-----------------\")\n",
    "    pairs_df = get_pairs(corpus_df)\n",
    "    mfp = get_most_frequent_pair(pairs_df)\n",
    "    print(f\"Most frequent pair: {mfp}\\n\")\n",
    "    corpus_df = update_corpus(corpus_df, mfp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbols</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>[s, a, i, d]</td>\n",
       "      <td>2174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>[p, e, o, p, l, e]</td>\n",
       "      <td>1858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>[w, o, m, en]</td>\n",
       "      <td>1769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[n, e, e, d]</td>\n",
       "      <td>1354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[f, a, m, i, l, i, es]</td>\n",
       "      <td>1347</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    symbols  frequency\n",
       "233            [s, a, i, d]       2174\n",
       "132      [p, e, o, p, l, e]       1858\n",
       "101           [w, o, m, en]       1769\n",
       "1              [n, e, e, d]       1354\n",
       "16   [f, a, m, i, l, i, es]       1347"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salida \n",
    "- Se obtiene un nuevo vocabulario $\\Sigma'$ donde se indican las sub-palabras más frecuentes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigma P (31)\n",
      "['a', 'b', 'c', 'd', 'e', 'en', 'er', 'es', 'f', 'g', 'h', 'i', 'in', 'j', 'k', 'l', 'm', 'n', 'o', 'on', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b</td>\n",
       "      <td>135429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>en</td>\n",
       "      <td>133148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>m</td>\n",
       "      <td>112524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c</td>\n",
       "      <td>105929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>99177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   symbol  frequency\n",
       "1       b     135429\n",
       "5      en     133148\n",
       "16      m     112524\n",
       "2       c     105929\n",
       "0       a      99177"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigma_p_dict = dict()\n",
    "for _, row in corpus_df.iterrows():\n",
    "    symbols = row['symbols']\n",
    "    freq = row['frequency']\n",
    "    for s in symbols:\n",
    "        if s not in sigma_p_dict:\n",
    "            sigma_p_dict[s] = 0\n",
    "        sigma_p_dict[s] += freq\n",
    "    \n",
    "sigma_p = sorted(list(sigma_p_dict.keys()))\n",
    "print(f\"Sigma P ({len(sigma_p)})\\n{sigma_p}\")\n",
    "\n",
    "sigma_p_df = pd.DataFrame({\n",
    "    'symbol': sigma_p,\n",
    "    'frequency': list(sigma_p_dict.values())\n",
    "})\n",
    "sigma_p_df = sigma_p_df.sort_values(by='frequency', ascending=False)\n",
    "sigma_p_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbols</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>[s, a, i, d]</td>\n",
       "      <td>2174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>[p, e, o, p, l, e]</td>\n",
       "      <td>1858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>[w, o, m, en]</td>\n",
       "      <td>1769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[n, e, e, d]</td>\n",
       "      <td>1354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[f, a, m, i, l, i, es]</td>\n",
       "      <td>1347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17756</th>\n",
       "      <td>[s, o, l, a, n, a]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17757</th>\n",
       "      <td>[c, on, s, i, d, er, a, b, l, y]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17759</th>\n",
       "      <td>[l, o, w, g, r, o, w, t, h]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17760</th>\n",
       "      <td>[f, o, u, r, p, a, r, t]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30740</th>\n",
       "      <td>[c, i, t, i, z, en, en, g, a, g, e, m, en, t]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30741 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             symbols  frequency\n",
       "233                                     [s, a, i, d]       2174\n",
       "132                               [p, e, o, p, l, e]       1858\n",
       "101                                    [w, o, m, en]       1769\n",
       "1                                       [n, e, e, d]       1354\n",
       "16                            [f, a, m, i, l, i, es]       1347\n",
       "...                                              ...        ...\n",
       "17756                             [s, o, l, a, n, a]          1\n",
       "17757               [c, on, s, i, d, er, a, b, l, y]          1\n",
       "17759                    [l, o, w, g, r, o, w, t, h]          1\n",
       "17760                       [f, o, u, r, p, a, r, t]          1\n",
       "30740  [c, i, t, i, z, en, en, g, a, g, e, m, en, t]          1\n",
       "\n",
       "[30741 rows x 2 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e8e5b3663f46d3e30364c3fda14ff5830effa7f7e28c52bdd1713a14cbd3cb6a"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
