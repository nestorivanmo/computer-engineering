{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práctica 2 - Word2Vec\n",
    "\n",
    "- Martínez Ostoa Néstor I.\n",
    "- Procesamiento de Lenguaje Natural\n",
    "- IeC - FI - UNAM\n",
    "--- \n",
    "\n",
    "**Objetivo:** a partir del corpus seleccionado en la práctica 1, realizar un modelo de embeddings basado en Word2Vec (no es necesario usar Negative Sampling). De manera general, hay que seguir los siguientes pasos: \n",
    "\n",
    "1. Trabajar con el corpus tokenizado\n",
    "2. Obtener los pares de entrenamiento a partir de los contextos\n",
    "3. Construir una red neuronal con una capa con 128 unidades ocutlas. Entrenar la red para obtener los embeddings\n",
    "4. Evaluar el modelo (capa de salida) con Entropía y/o Perplejidad\n",
    "5. Visualizar los embeddings\n",
    "6. Guardar los vectores de la capa de embeddings asociados a las palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
